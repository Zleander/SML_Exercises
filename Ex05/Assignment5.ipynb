{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-96d2211a5a01c5d4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Assignment 5 {-}\n",
    "## Due May 23 at 12:00 {-}\n",
    "\n",
    "Please note: \n",
    "\n",
    "- Read the instructions in the exercise PDF and in this notebook carefully.\n",
    "- Add your solutions *only* at `YOUR CODE HERE`/`YOUR ANSWER HERE` and remove the corresponding `raise NotImplementedError()`.\n",
    "- Do not chance the provided code and text, if not stated.\n",
    "- Do not *add* or *delete* cells.\n",
    "- Do not `import` additional functionality. \n",
    "- Before submitting: Please make sure, that your notebook can be executed from top to bottom `Menu -> Kernel -> Restart & Run all`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1 (Lagrange multipliers, 2 points)\n",
    "\n",
    "\\begin{align*}\n",
    "    &\\max x+y \\\\\n",
    "    &\\text{s.t. } x^2+2y^2 \\leq 5 \\\\\n",
    "    L(x, y, \\alpha) &= (x+y) - \\alpha (x^2+2y^2-5) \\\\\n",
    "    \\frac{\\partial L}{\\partial x} &= 1  - 2\\alpha x \\overset{!}{=} 0 \\\\\n",
    "    \\alpha &= \\frac{1}{2x} \\\\\n",
    "    \\frac{\\partial L}{\\partial y} &= 1  - 4\\alpha y \\overset{!}{=} 0 \\\\\n",
    "    \\alpha &= \\frac{1}{4y} \\\\\n",
    "    \\frac{1}{2x} &= \\frac{1}{4y} \\\\\n",
    "    x &= 2y \\\\\n",
    "    L(y,\\alpha) &= (2y+y) - \\alpha ((2y)^2+2y^2-5) \\\\\n",
    "    \\frac{\\partial L}{\\partial \\alpha} &= (2y)^2+2y^2-5 \\overset{!}{=} 0\\\\\n",
    "    4y^2 + 2y^2 &= 5 \\\\\n",
    "    y^2 &= \\frac{5}{6} \\\\\n",
    "    y &= \\sqrt{\\frac{5}{6}} \\\\\n",
    "    x &= 2\\sqrt{\\frac{5}{6}} = \\sqrt{\\frac{10}{3}} \\\\\n",
    "    \\alpha &= \\frac{1}{2x} \\geq 0 \\\\\n",
    "\\end{align*}\n",
    "The constraint is active. Geometrically this can be explained, by thinking about the uncontrained solution of $\\max x+y$ and the ellipsoid, that $x^2+2y^2=5$ describes. We can then easily see, that the solution of the constrained problem lies at a point on said ellipsoid, not inside it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2 (Linear and quadratic programs, 3+1+1=5 points)\n",
    "## a)\n",
    "<!---\n",
    "\\begin{align*}\n",
    "    &\\min_{x\\in \\mathbb{R}^n} c^T x \\\\\n",
    "    \\text{s.t. }\n",
    "    &Ax \\leq b \\\\\n",
    "    &x \\geq 0 \\\\\n",
    "    L(\\alpha, \\beta, x) &= c^Tx - \\alpha^T(Ax - b) + \\beta^T x \\\\\n",
    "    &= c^Tx - \\alpha^T(Ax - b) + \\beta^T x \\\\\n",
    "    \\frac{\\partial L}{\\partial x} &= c^T - \\alpha^T A + \\beta^T \\overset{!}{=} 0 \\\\\n",
    "    \\frac{\\partial L}{\\partial \\alpha} &= Ax-b \\overset{!}{=} 0 \\\\\n",
    "    \\frac{\\partial L}{\\partial \\beta} &= x \\overset{!}{=} 0 \\\\\n",
    "    \\alpha^T &= (\\beta^T + c^T)A^{-1} \\\\\n",
    "    g(\\alpha, \\beta) &= c^Tx - \\left((\\beta^T + c^T)A^{-1} \\right)Ax + \\beta^Tx \\\\\n",
    "    \\text{Dual:} \\\\\n",
    "    g(\\alpha, \\beta) &= g\n",
    "\\end{align*}\n",
    "--->\n",
    "\n",
    "## b) \n",
    "\\begin{align*}\n",
    "    E &= \\frac{1}{2}x^TQx + c^Tx \\\\\n",
    "    \\frac{\\partial E}{\\partial x} &= x^TQ + c \\\\\n",
    "    \\frac{\\partial^2 E}{\\partial x^2} &= Q\n",
    "\\end{align*}\n",
    "When we derive the problem twice, we can see the $Q$ is the Hessian matrix. Therefore we require $Q$ to be positive semi-definite for the problem to be convex.\n",
    "\n",
    "## c)\n",
    "\n",
    "This means that, as the solutions for the dual and the primal are equal, it does not matter wether we solve the primal or the dual problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3 (Primal hard margin SVM problem, 3 points)\n",
    "\n",
    "Any solution of this problem is subject to:  \n",
    "$$Y_i(w^TX_i+b)\\geq1 \\;\\forall i=1,\\dots,n$$  \n",
    "If the hyperplane is not in canonical representation, it holds:\n",
    "$$\\min_{i} |w^TX_i+b| \\neq 1 $$  \n",
    "And thus, because $Y_i \\in {-1,1}$:  \n",
    "$$Y_i(w^TX_i+b)>1 \\;\\forall i=1,\\dots,n$$  \n",
    "Then $$\\exists \\hat w \\text{ with } \\frac{1}{2}\\|\\hat w\\|^2 < \\frac{1}{2}\\| w\\|^2 $$  \n",
    "in other words, $w$ does not minimize the objective, and is not a solution.  \n",
    "While $$Y_i(\\hat w^TX_i+b)\\geq1 \\;\\forall i=1,\\dots,n$$\n",
    "and $$\\exists i\\; Y_i(\\hat w^TX_i+b)=1 $$  \n",
    "and therefore $$\\min_{i} |\\hat{w}^TX_i+b| = 1$$\n",
    "in other words, $\\hat w$ is a valid solution and a canonical Hyperplane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ffb10fbc071fc814",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import time \n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy.testing import assert_equal, assert_almost_equal\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#  Hide warnings of LinearSVC, LogisticRegression\n",
    "\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=ConvergenceWarning)\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-65c9e677a5c1d059",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## a) Know the Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-0da6208813948939",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "- **Features:**  \n",
    "    Characteristics of Cell nuclei in an image of a possible breast cancer sample, such as size, texture, compactness, ...  \n",
    "    For all of these, the mean, std and worst value is given.\n",
    "- **Labels:**  \n",
    "    Diagnosis, wheter sampled tumor is malignant (non-cancerous) or benign (cancerous)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f454aa4ab0e7abc6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "dataset = load_breast_cancer()\n",
    "\n",
    "xs = dataset.data\n",
    "ys = dataset.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split `xs, ys` to the training set `xs_train, ys_train` (size $70\\%$) and the test set `xs_test, ys_test` (size $30\\%$) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a440cbfbbb0a67b2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## b)/c) Optimize the Hyperparameters: Linear SVM vs Logistic Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a7d3b8a7e75f7895",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We can do better than  0.03508771929824561\n"
     ]
    }
   ],
   "source": [
    "# center and normalize\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(xs)\n",
    "xs = scaler.transform(xs)\n",
    "\n",
    "# split into training and test test\n",
    "n_train = int(len(xs) * .7)\n",
    "\n",
    "xs_train, xs_test = xs[:n_train], xs[n_train:]\n",
    "ys_train, ys_test = ys[:n_train], ys[n_train:]\n",
    "\n",
    "# evaluate standard SVM\n",
    "svm_estimator = LinearSVC().fit(xs_train,ys_train)\n",
    "print('We can do better than ', np.mean(svm_estimator.predict(xs_test) != ys_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find good hyperparameters *without* the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0493355d0168522f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation errors of best model:\n",
      "Linear SVM 0.0226, with param C=0.1\n",
      "Logistic Regression 0.0251, with param C=0.4037\n"
     ]
    }
   ],
   "source": [
    "# DO NOT USE xs_test, ys_test here!\n",
    "# Please make your optimization reproducable (e.g. set random_state, seed, …)\n",
    "# LinearSVC and LogisticRegression\n",
    "seed = 42\n",
    "\n",
    "no_CV_parts = 5\n",
    "\n",
    "best_params_svm, best_params_lr = {}, {}\n",
    "cv_errors_svm, cv_errors_lr = [],[]\n",
    "\n",
    "Cs =  [0.001, 0.0035, 0.01, 0.4037, 0.1, 1, 10, 100, 1000]\n",
    "\n",
    "np.random.seed(seed)\n",
    "indices = np.array(range(len(xs_train)))\n",
    "np.random.shuffle(indices)\n",
    "xss_train = xs_train[indices]\n",
    "yss_train = ys_train[indices]\n",
    "\n",
    "splits = [int(len(xs_train) * 1/no_CV_parts * i) for i in range(no_CV_parts+1)]\n",
    "\n",
    "xs_parts = [xss_train[splits[i]: splits[i+1]] for i in range(no_CV_parts)]\n",
    "ys_parts = [yss_train[splits[i]: splits[i+1]] for i in range(no_CV_parts)]\n",
    "\n",
    "for C in Cs:\n",
    "    cv_errors_svm_all = []\n",
    "    for i in range(len(parts)):\n",
    "        xp_train = np.concatenate([xs_parts[j] for j in range(no_CV_parts) if j!=i])\n",
    "        xp_test = xs_parts[i]\n",
    "        \n",
    "        yp_train = np.concatenate([ys_parts[j] for j in range(no_CV_parts) if j!=i])\n",
    "        yp_test = ys_parts[i]\n",
    "        \n",
    "        svm_estimator = LinearSVC(C=C, random_state=seed).fit(xp_train, yp_train)\n",
    "        cv_errors_svm_all.append(1-svm_estimator.score(xp_test, yp_test))\n",
    "    cv_errors_svm.append(np.mean(cv_errors_svm_all))\n",
    "    \n",
    "    cv_errors_lr_all = []\n",
    "    for i in range(len(parts)):\n",
    "        xp_train = np.concatenate([xs_parts[j] for j in range(no_CV_parts) if j!=i])\n",
    "        xp_test = xs_parts[i]\n",
    "        \n",
    "        yp_train = np.concatenate([ys_parts[j] for j in range(no_CV_parts) if j!=i])\n",
    "        yp_test = ys_parts[i]\n",
    "        \n",
    "        lr = LogisticRegression(C=C, random_state=seed).fit(xp_train, yp_train)\n",
    "        cv_errors_lr_all.append(1-lr.score(xp_test, yp_test))\n",
    "    cv_errors_lr.append(np.mean(cv_errors_lr_all))\n",
    "    \n",
    "\n",
    "svm_i = np.argmin(cv_errors_svm)\n",
    "best_params_svm = {'C': Cs[svm_i]}\n",
    "\n",
    "\n",
    "lr_i = np.argmin(cv_errors_lr)\n",
    "best_params_lr = {'C': Cs[lr_i]}\n",
    "\n",
    "print(f\"Cross validation errors of best model:\\nLinear SVM {cv_errors_svm[svm_i]:.4f}, with param C={best_params_svm['C']}\\nLogistic Regression {cv_errors_lr[lr_i]:.4f}, with param C={best_params_lr['C']}\")\n",
    "\n",
    "best_estimator_svm = LinearSVC(**best_params_svm, random_state=seed).fit(xs_train, ys_train)\n",
    "best_estimator_lr = LogisticRegression(**best_params_lr, random_state=seed).fit(xs_train, ys_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-213d9fdca48368f0",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test errors of best model:\n",
      "Linear SVM:0.0117 \n",
      "Logistic Regression: 0.0292\n"
     ]
    }
   ],
   "source": [
    "# if you did not solve the cross validation, use this:\n",
    "svm_estimator = LinearSVC(C=0.0035, random_state=42).fit(xs_train, ys_train)\n",
    "lr_estimator = LogisticRegression(C=0.4037,random_state=42).fit(xs_train, ys_train)\n",
    "# else, use this:\n",
    "\n",
    "#svm_estimator = best_estimator_svm\n",
    "#lr_estimator = best_estimator_lr\n",
    "\n",
    "svm_score = svm_estimator.score(xs_test, ys_test)\n",
    "lr_score = lr_estimator.score(xs_test, ys_test)\n",
    "\n",
    "print(f\"Test errors of best model:\\nLinear SVM:{1-svm_score:.4f} \\nLogistic Regression: {1-lr_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-563e6d1de9e41fbf",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "What do you observe and why?\n",
    "\n",
    "Answer: YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a7fd6a82e440e12c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## d) State concerns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-5afbd54df2ee393d",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "1. **Ethical:** \n",
    "    YOUR ANSWER HERE\n",
    "\n",
    "2. **Technical/Statistical:**\n",
    "    YOUR ANSWER HERE\n",
    "\n",
    "3. **Any:**\n",
    "    YOUR ANSWER HERE"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
